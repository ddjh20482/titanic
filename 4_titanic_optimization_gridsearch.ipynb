{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "This part will show you how hyperparameter-tuning is done. At the end test scores will be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# drop irrelevant columns\n",
    "df.drop(columns = [\"Name\", \"PassengerId\", \"Cabin\", \"Ticket\"], inplace=True)\n",
    "\n",
    "# handling missing values\n",
    "df.Age.fillna(df.Age.mean(), inplace=True)\n",
    "df.Embarked.fillna('N/A', inplace=True)\n",
    "\n",
    "# separating target and features\n",
    "X = df.drop(columns = [\"Survived\"])\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# labeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# oversampling\n",
    "from imblearn.over_sampling import SMOTE \n",
    "smote = SMOTE(random_state=1)\n",
    "\n",
    "# classifier model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# importing function to display scores\n",
    "import data_preparation as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_labeled = X_train.copy()\n",
    "X_test_labeled = X_test.copy()\n",
    "\n",
    "col = [\"Sex\", \"Embarked\"]\n",
    "for c in col:\n",
    "    X_train_labeled[c] = le.fit_transform(X_train[c].astype('str'))\n",
    "    X_test_labeled[c] = le.transform(X_test[c].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(random_state=1)),\n",
       "                ('gbc', GradientBoostingClassifier(random_state=1))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('smote', smote),\n",
    "                       ('gbc', GradientBoostingClassifier(random_state=1))])\n",
    "\n",
    "pipe.fit(X_train_labeled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('smote', SMOTE(random_state=1)),\n",
      "                ('gbc', GradientBoostingClassifier(random_state=1))])\n",
      "\n",
      "CV score:     83.03%\n",
      "X-test score: 81.61%\n",
      "RMSE:         0.4288\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       421\n",
      "           1       0.90      0.84      0.87       247\n",
      "\n",
      "    accuracy                           0.91       668\n",
      "   macro avg       0.90      0.89      0.90       668\n",
      "weighted avg       0.91      0.91      0.90       668\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       128\n",
      "           1       0.86      0.68      0.76        95\n",
      "\n",
      "    accuracy                           0.82       223\n",
      "   macro avg       0.83      0.80      0.81       223\n",
      "weighted avg       0.82      0.82      0.81       223\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.scores(X_train_labeled, y_train, X_test_labeled, y_test, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gbc__loss': 'exponential',\n",
       " 'gbc__max_depth': 5,\n",
       " 'gbc__max_features': None,\n",
       " 'gbc__min_samples_leaf': 1,\n",
       " 'gbc__min_samples_split': 3,\n",
       " 'gbc__n_estimators': 100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# instantiate grid search for hyperparameter tuning\n",
    "param = {'gbc__loss': ['log_loss', 'deviance', 'exponential'],\n",
    "         'gbc__n_estimators':  [100, 200, 300],\n",
    "         'gbc__min_samples_split': [2, 3, 4, 5],\n",
    "         'gbc__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "         'gbc__max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "         'gbc__max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "        }\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param,\n",
    "                  cv=3)\n",
    "\n",
    "gs.fit(X_train_labeled, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('smote', SMOTE(random_state=1)),\n",
      "                ('gbc',\n",
      "                 GradientBoostingClassifier(loss='exponential', max_depth=5,\n",
      "                                            min_samples_split=3,\n",
      "                                            random_state=1))])\n",
      "\n",
      "CV score:     83.23%\n",
      "X-test score: 77.58%\n",
      "RMSE:         0.4735\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       421\n",
      "           1       0.97      0.94      0.96       247\n",
      "\n",
      "    accuracy                           0.97       668\n",
      "   macro avg       0.97      0.96      0.97       668\n",
      "weighted avg       0.97      0.97      0.97       668\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       128\n",
      "           1       0.80      0.63      0.71        95\n",
      "\n",
      "    accuracy                           0.78       223\n",
      "   macro avg       0.78      0.76      0.76       223\n",
      "weighted avg       0.78      0.78      0.77       223\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking score with tuned model\n",
    "pipe_tuned = Pipeline(steps=[('smote', smote),\n",
    "                             ('gbc', GradientBoostingClassifier(random_state=1, \n",
    "                                                       loss = 'exponential',\n",
    "                                                       max_depth = 5,\n",
    "                                                       min_samples_split = 3\n",
    "                                                      ))])\n",
    "\n",
    "pipe_tuned.fit(X_train_labeled, y_train)\n",
    "dp.scores(X_train_labeled, y_train, X_test_labeled, y_test, pipe_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test score became smaller after tuning. We will stick to the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = pd.concat([pd.DataFrame(X_train_labeled.columns, columns = ['Features']),\n",
    "                       pd.DataFrame(pipe_tuned.steps[1][1].feature_importances_, columns = ['FI_score'])\n",
    "                       ],\n",
    "                      axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>FI_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.381585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.233097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.218864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.071828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.052864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.029648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.012114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  FI_score\n",
       "1       Sex  0.381585\n",
       "2       Age  0.233097\n",
       "5      Fare  0.218864\n",
       "0    Pclass  0.071828\n",
       "3     SibSp  0.052864\n",
       "6  Embarked  0.029648\n",
       "4     Parch  0.012114"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_impt.sort_values(by='FI_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see sex, age, and fare has the highest importance in the analysis. We see sex and fare in both classification analysis and heatmap, but it seems classification takes age information more seriously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
