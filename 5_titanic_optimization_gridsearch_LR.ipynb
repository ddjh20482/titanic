{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is a repeated step of part 4 using logistic regression. This part was made by mistake as logistic regression had higher test score, but I found out gradient boosting had better test score after correction in the coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "df.drop(columns = [\"Name\", \"PassengerId\", \"Cabin\", \"Ticket\"], inplace=True)\n",
    "\n",
    "df.Age.fillna(df.Age.mean(), inplace=True)\n",
    "df.Embarked.fillna('N/A', inplace=True)\n",
    "\n",
    "X = df.drop(columns = [\"Survived\"])\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "smote = SMOTE(random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import data_preparation as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_labeled = X_train.copy()\n",
    "X_test_labeled = X_test.copy()\n",
    "\n",
    "col = [\"Sex\", \"Embarked\"]\n",
    "for c in col:\n",
    "    X_train_labeled[c] = le.fit_transform(X_train[c].astype('str'))\n",
    "    X_test_labeled[c] = le.transform(X_test[c].astype('str'))\n",
    "    \n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train_labeled, y_train) \n",
    "\n",
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(random_state=1)),\n",
       "                ('lr', LogisticRegression(random_state=1))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('smote', smote),\n",
    "                       ('lr', LogisticRegression(random_state=1))])\n",
    "\n",
    "pipe.fit(X_train_labeled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('smote', SMOTE(random_state=1)),\n",
      "                ('lr', LogisticRegression(random_state=1))])\n",
      "\n",
      "CV score:     81.24%\n",
      "X-test score: 79.82%\n",
      "RMSE:         0.4492\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       421\n",
      "           1       0.70      0.74      0.72       247\n",
      "\n",
      "    accuracy                           0.79       668\n",
      "   macro avg       0.77      0.78      0.77       668\n",
      "weighted avg       0.79      0.79      0.79       668\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       128\n",
      "           1       0.77      0.75      0.76        95\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.79      0.79      0.79       223\n",
      "weighted avg       0.80      0.80      0.80       223\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.scores(X_train_labeled, y_train, X_test_labeled, y_test, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__max_iter': 100, 'lr__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# instantiate grid search for hyperparameter tuning\n",
    "param = {'lr__max_iter': [100, 200, 300],\n",
    "         'lr__solver':  ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "        }\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param,\n",
    "                  cv=3)\n",
    "\n",
    "gs.fit(X_train_labeled, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('smote', SMOTE(random_state=1)),\n",
      "                ('lr', LogisticRegression(random_state=1, solver='newton-cg'))])\n",
      "\n",
      "CV score:     81.04%\n",
      "X-test score: 79.82%\n",
      "RMSE:         0.4492\n",
      "\n",
      "Train score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       421\n",
      "           1       0.70      0.74      0.72       247\n",
      "\n",
      "    accuracy                           0.79       668\n",
      "   macro avg       0.77      0.78      0.77       668\n",
      "weighted avg       0.79      0.79      0.79       668\n",
      "\n",
      "\n",
      "\n",
      "X-test score\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       128\n",
      "           1       0.77      0.75      0.76        95\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.79      0.79      0.79       223\n",
      "weighted avg       0.80      0.80      0.80       223\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tuned = Pipeline(steps=[('smote', smote),\n",
    "                             ('lr', LogisticRegression(random_state=1, solver = 'newton-cg'))])\n",
    "\n",
    "pipe_tuned.fit(X_train_labeled, y_train)\n",
    "dp.scores(X_train_labeled, y_train, X_test_labeled, y_test, pipe_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smote', SMOTE(random_state=1)),\n",
       " ('lr', LogisticRegression(random_state=1, solver='newton-cg'))]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.14105186e+00, -2.92995323e+00, -5.00089387e-02,\n",
       "        -5.22121987e-01, -4.89563975e-02,  7.09411601e-04,\n",
       "        -1.98396046e-01]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps[1][1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = pipe.steps[0][1].fit_sample(X_train_labeled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = np.std(X_train_resampled, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = pd.DataFrame({'std': np.std(X_train_resampled, 0).values,\n",
    "                          'coef': pipe_tuned.steps[1][1].coef_[0]},\n",
    "                         index=feature_imp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt[\"feat_imp\"] = np.absolute(feat_impt.iloc[:,0] * feat_impt.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>coef</th>\n",
       "      <th>feat_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.498169</td>\n",
       "      <td>-2.929953</td>\n",
       "      <td>1.459611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.847493</td>\n",
       "      <td>-1.141052</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>13.666580</td>\n",
       "      <td>-0.050009</td>\n",
       "      <td>0.683451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.939060</td>\n",
       "      <td>-0.522122</td>\n",
       "      <td>0.490304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>1.162025</td>\n",
       "      <td>-0.198396</td>\n",
       "      <td>0.230541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.750605</td>\n",
       "      <td>-0.048956</td>\n",
       "      <td>0.036747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>48.139221</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.034151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                std      coef  feat_imp\n",
       "Sex        0.498169 -2.929953  1.459611\n",
       "Pclass     0.847493 -1.141052  0.967033\n",
       "Age       13.666580 -0.050009  0.683451\n",
       "SibSp      0.939060 -0.522122  0.490304\n",
       "Embarked   1.162025 -0.198396  0.230541\n",
       "Parch      0.750605 -0.048956  0.036747\n",
       "Fare      48.139221  0.000709  0.034151"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_impt.sort_values(by='feat_imp', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
